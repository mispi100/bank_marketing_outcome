{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a3b38e",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4671b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00887568",
   "metadata": {},
   "source": [
    "# Read in Data and Split in Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1f6a1e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bank+marketing/bank/bank_preprocessed.csv\")\n",
    "X = df.drop(columns = \"y\")\n",
    "y = df[\"y\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5d00e6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 3616\n",
      "Number of testing examples: 905\n",
      "Number of features = 43\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of training examples: \" + str(X_train.shape[0]))\n",
    "print (\"Number of testing examples: \" + str( X_test.shape[0]))\n",
    "print (\"Number of features = \" + str(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd731cc",
   "metadata": {},
   "source": [
    "# Define Functions for Flat Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "09870814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    z = np.array(z, dtype=np.float64)\n",
    "    z = np.clip(z, -500, 500)\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"Initialize the weights and bias to zero.\"\"\"\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    return w, b\n",
    "\n",
    "def initialize_with_random(dim):\n",
    "    \"\"\"Initialize the weights with small random values and bias to zero.\"\"\"\n",
    "    w = np.random.randn(dim, 1) * np.sqrt(1. / dim)\n",
    "    b = 0.0\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    return w, b\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    m = X.shape[1]   \n",
    "    A = sigmoid(np.dot(w.T, X) + b)                         # compute activation\n",
    "    epsilon = 1e-8\n",
    "    cost = -1/m * np.sum(Y * np.log(A + epsilon) + (1-Y) * np.log(1 - A + epsilon)) # compute cost\n",
    "\n",
    "    dw = (1 / m ) * np.dot(X , (A - Y).T)\n",
    "    db = (1 / m) * np.sum(A - Y)\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"Optimize weights using gradient descent.\"\"\"\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        w = w - learning_rate * dw\n",
    "        if i % 500 == 0:\n",
    "            costs.append(cost)\n",
    "        if print_cost and i % 500 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs\n",
    "\n",
    "def predict(w, b, X):\n",
    "    \"\"\"Make predictions using learned weights and bias.\"\"\"\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    A = sigmoid( np.dot(w.T, X) + b)\n",
    "    for i in range(A.shape[1]):\n",
    "        Y_prediction[0, i] = 1 if A[0, i] > 0.5 else 0\n",
    "        pass\n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "081cc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.1, print_cost = True):\n",
    "    w, b = initialize_with_random(X_train.shape[0])\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost = print_cost)\n",
    "    \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d6174",
   "metadata": {},
   "source": [
    "# Shape and Normalize Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "69f979e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "000b14bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "X_train_scaled = X_train_scaled.T\n",
    "X_test_scaled = X_test_scaled.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfaf123",
   "metadata": {},
   "source": [
    "# Apply to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f8fd4bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 2.256489\n",
      "Cost after iteration 500: 3.151718\n",
      "Cost after iteration 1000: 3.087345\n",
      "Cost after iteration 1500: 3.039072\n",
      "Cost after iteration 2000: 3.055508\n",
      "Cost after iteration 2500: 2.654337\n",
      "Cost after iteration 3000: 2.809273\n",
      "Cost after iteration 3500: 2.987681\n",
      "Cost after iteration 4000: 2.995030\n",
      "Cost after iteration 4500: 2.942745\n",
      "train accuracy: 83.73893805309734 %\n",
      "test accuracy: 84.1988950276243 %\n"
     ]
    }
   ],
   "source": [
    "d = model(X_train, y_train, X_test, y_test, num_iterations = 5000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2d885be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC:  0.517\n"
     ]
    }
   ],
   "source": [
    "y_pred = pd.Series(d[\"Y_prediction_test\"].flatten())\n",
    "roc_value = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC AUC: \", np.round(roc_value, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "25b56e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       807\n",
      "           1       0.15      0.10      0.12        98\n",
      "\n",
      "    accuracy                           0.84       905\n",
      "   macro avg       0.52      0.52      0.52       905\n",
      "weighted avg       0.81      0.84      0.83       905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "957e94bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.846604\n",
      "Cost after iteration 500: 0.690885\n",
      "Cost after iteration 1000: 0.646310\n",
      "Cost after iteration 1500: 0.631545\n",
      "Cost after iteration 2000: 0.625368\n",
      "Cost after iteration 2500: 0.622305\n",
      "Cost after iteration 3000: 0.620590\n",
      "Cost after iteration 3500: 0.619529\n",
      "Cost after iteration 4000: 0.618815\n",
      "Cost after iteration 4500: 0.618303\n",
      "Cost after iteration 5000: 0.617915\n",
      "Cost after iteration 5500: 0.617610\n",
      "Cost after iteration 6000: 0.617362\n",
      "Cost after iteration 6500: 0.617157\n",
      "Cost after iteration 7000: 0.616983\n",
      "Cost after iteration 7500: 0.616834\n",
      "Cost after iteration 8000: 0.616705\n",
      "Cost after iteration 8500: 0.616592\n",
      "Cost after iteration 9000: 0.616492\n",
      "Cost after iteration 9500: 0.616403\n",
      "Cost after iteration 10000: 0.616323\n",
      "Cost after iteration 10500: 0.616250\n",
      "Cost after iteration 11000: 0.616185\n",
      "Cost after iteration 11500: 0.616125\n",
      "Cost after iteration 12000: 0.616070\n",
      "Cost after iteration 12500: 0.616020\n",
      "Cost after iteration 13000: 0.615974\n",
      "Cost after iteration 13500: 0.615931\n",
      "Cost after iteration 14000: 0.615891\n",
      "Cost after iteration 14500: 0.615854\n",
      "Cost after iteration 15000: 0.615819\n",
      "Cost after iteration 15500: 0.615787\n",
      "Cost after iteration 16000: 0.615756\n",
      "Cost after iteration 16500: 0.615728\n",
      "Cost after iteration 17000: 0.615701\n",
      "Cost after iteration 17500: 0.615676\n",
      "Cost after iteration 18000: 0.615652\n",
      "Cost after iteration 18500: 0.615630\n",
      "Cost after iteration 19000: 0.615608\n",
      "Cost after iteration 19500: 0.615588\n",
      "train accuracy: 78.76106194690266 %\n",
      "test accuracy: 78.89502762430939 %\n"
     ]
    }
   ],
   "source": [
    "d = model(X_train_scaled, y_train, X_test_scaled, y_test, num_iterations = 20000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e2f544e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC:  0.823\n"
     ]
    }
   ],
   "source": [
    "y_pred = pd.Series(d[\"Y_prediction_test\"].flatten())\n",
    "roc_value = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC AUC: \", np.round(roc_value, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4c7f0d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       807\n",
      "           1       0.32      0.87      0.47        98\n",
      "\n",
      "    accuracy                           0.79       905\n",
      "   macro avg       0.65      0.82      0.67       905\n",
      "weighted avg       0.91      0.79      0.83       905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80463e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abaf5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
